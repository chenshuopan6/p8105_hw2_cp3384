hw2_p8105
================
Chenshuo Pan
2023-09-26

# Question1:

``` r
library(tidyverse)
library(dplyr)
library(readxl)
```

``` r
#read dataset
pols_month <- read.csv("./data/pols-month.csv")
snp <- read.csv("./data/snp.csv")
unemployment <- read.csv("./data/unemployment.csv")
```

``` r
#tidy pols dataset
pols_month_clean <- 
  pols_month%>%
#clean column names
  janitor::clean_names()%>%
#separate mon column into year, month and day
  separate(col = mon , into = c('year','month','day'),sep = '-',convert = TRUE)%>%
#turn the number of month to the month in english
  mutate(month = month.name[month])%>%
#create president variable to present club
  mutate(president = case_when(
      prez_dem == 1 ~ "dem",
      prez_gop %in% c(1,2) ~ "gop"
    ))%>%
#remove these three variables
  select(-prez_dem, -prez_gop,-day)%>%
#create a variable using year and month values
  mutate(date = paste(year,month,sep = "-"))%>%
  arrange(year,match(month,month.name))


#The reason why I do not use Date variable is that We don’t need to determine which day it is because we have excluded the day column. If you need date, you can run the following code. Please note that it is running under an English operating system.
#mutate(date2 = as.Date(paste(date,"01",sep = "-"),format = "%Y-%B-%d"))
```

``` r
#do the same thing to snp as pols dataset
snp_clean <- 
  snp%>%
  janitor::clean_names()%>%
  separate(col = date , into = c('month','day','year'),sep = '/',convert = TRUE)%>%
  mutate(month = month.name[month])%>%
  #After observation, there are data from 50-99 and 00-15 in the year column. Based on the actual situation, we distribute the two plus 2000 and 1900 to represent the year.
  mutate(year = case_when(
    between(year, 0, 15) ~ year + 2000,
    between(year, 50, 99) ~ year + 1900,
    TRUE ~ year))%>%
  relocate(year,month)%>%
  select(-day)%>%
  #Sort by year and month, use match to sort by month instead of alphabetically
  arrange(year,match(month,month.name))%>%
  mutate(date = paste(year,month,sep = "-"))
```

``` r
#Clean the unemployment dataset
unemployment_clean <- 
  unemployment%>%
#convert wider table to longer
  pivot_longer(cols = Jan:Dec,names_to = 'month',values_to = 'percent')%>%
#convert month abbreviation to full name
  mutate(month = month.name[match(month,month.abb)])%>%
  mutate(date = paste(Year,month,sep = "-"))%>%
  arrange(Year,match(month,month.name))
```

``` r
#join all 3 tables together
combine_table <- pols_month_clean%>%select(-year,-month)%>%
  left_join(snp_clean%>%select(-year,-month),by = "date")%>%
  left_join(unemployment_clean%>%select(-Year,-month),,by = 'date')
```

**Write a short paragraph about these datasets. Explain briefly what
each dataset contained, and describe the resulting dataset**

(All data sets described below are unprocessed)

`pols-month.csv` dataset contains 822 rows and 9 columns. The year range
is between `range(pols_month$mon)`. key variables are: mon, prez_gop,
gov_gop, sen_gop, rep_gop, prez_dem, gov_dem, sen_dem, rep_dem.I
decomposed the `mon` column into `year` `month` and created a
`president` variable to replace `prez_dem`, `prez_gop`, and finally
added a `date` variable to merge the data frames

`snp.csv` dataset contains 787 rows and 2 columns. The year range is
between and . key variables are: date, close. Here I decomposed the
`Date` column into `year` `month` and finally added a `date` variable to
merge the data frames

`unemployment.csv` dataset contains 68 rows and 13 columns. The year
range is between 4 and NA. key variables are: Year, Jan, Feb, Mar, Apr,
May, Jun, Jul, Aug, Sep, Oct, Nov, Dec. Here A length-width table
conversion was performed, and the month variable name was transferred to
the `month` column to become a variable, and the retained number was
called `percent`and finally added a `date` variable to merge the data
frames

Finally, I combined all these three dataset into `combine_table` , which
has 822 rows and 10 columns.key variables are: gov_gop, sen_gop,
rep_gop, gov_dem, sen_dem, rep_dem, president, date, close, percent.

# Question2:

``` r
#load the trash, professor, gwynnda sheet
trash <- read_excel("./data/202309 Trash Wheel Collection Data.xlsx",
                    sheet = 'Mr. Trash Wheel',
                    range = "A2:N586",
                    col_names = TRUE
                    )

professor <- read_excel("./data/202309 Trash Wheel Collection Data.xlsx", 
                        sheet = 'Professor Trash Wheel',
                        range = "A2:M108",
                        col_names = TRUE)

gwynnda <- read_excel("./data/202309 Trash Wheel Collection Data.xlsx", 
                      sheet = 'Gwynnda Trash Wheel',
                      range = "A2:L157",
                      col_names = TRUE)
```

``` r
#clean trash table
trash_clean <- trash%>%
#Clean column names
  janitor::clean_names()%>%
#create homes_powered variables calculating the average family number can supply
#and add a label wheel_name to show where each data comes from.
  mutate(homes_powered = weight_tons * 500 / 30,
         wheel_name = "Mr")
```

``` r
#clean professor table
professor_clean <- professor%>%
  janitor::clean_names()%>%
#create homes_powered variables calculating the average family number can supply
#and add a label wheel_name to show where each data comes from.
  mutate(homes_powered = weight_tons * 500 / 30,
         wheel_name = "professor")
```

``` r
#clean gwynndatable
gwynnda_clean <-gwynnda%>%
  janitor::clean_names()%>%
#create homes_powered variables calculating the average family number can supply
#and add a label wheel_name to show where each data comes from.
  mutate(homes_powered = weight_tons * 500 / 30,
         wheel_name = "gwynnda")
```

``` r
#combine professor,trash and gwynnda dataset into one
combine_wheel <- gwynnda_clean%>%
  bind_rows(professor_clean)%>%
  bind_rows(trash_clean%>%mutate(year = as.numeric(year)))%>%
  arrange(date)
```

**Be sure to note the number of observations in the resulting dataset,
and give examples of key variables.** The Mr.Trash wheel sheet after
cleaning contains 584 rows and 15 columns

The Professor wheel sheet after cleaning contains 106 rows and 14
columns

The Gwynnda wheel sheet after cleaning contains 155 rows and 13 columns

The resulting dataset contains 845 rows and 15 columns.Which means there
are 845 observations. Some examples of key variables: `dumpster`
represents dumpter number.`Year,month,date` shows the time when data
been collected. `weight_tons` records the weight of the garbage,
`home_powered` calculates the number of households expected to be
supplied . `wheel_name`indicates which sheet this record comes
from.There are other variables include number of plastic bottles, etc.

**For available data, what was the total weight of trash collected by
Professor Trash Wheel?**

The total weight of trash collected by Professor Trash Wheel is
216.26tons

**What was the total number of cigarette butts collected by Gwynnda in
July of 2021?**

The total number of cigarette butts collected by Gwynnda in July of 2021
are 1.63^{4}

# Question3:

``` r
#load MCI_baseline csv file
baseline <- read.csv("./data/MCI_baseline.csv",
                      skip = 1,
                     na.strings = c("."))
```

``` r
# clean baseline dataset
baseline_clean <- baseline%>%
# clean column names
  janitor::clean_names()%>%
# encode sex =1 to Male and sex = 0 to Female
  mutate(sex = case_when(
      sex == 0 ~ "Female",
      sex == 1 ~ "Male"
    ),
# encode apoe4 =1 to APOE4 carrier and apoe4 =0 to Female
    apoe4 = case_when(
      apoe4 == 0 ~ "APOE4 non-carrier",
      apoe4 == 1 ~ "APOE4 carrier"
    ))
# remove any participants who do not meet the stated inclusion criteria
baseline_filter <-baseline_clean%>%
  filter(current_age < age_at_onset | is.na(age_at_onset))
```

**Discuss important steps in the import process and relevant features of
the dataset.**

The import steps in my view include how to convert `.` into `NA` and
appropriately encode sex and apoe4 columns. Here I use `case_when` to do
the convention.

This dataset has 483 rows , and 6 columns. After removing participants
who do not meet the stated inclusion criteria. The dataset keep 479
rows. The important variables in this dataset including : id,
current_age, sex, education, apoe4, age_at_onset

**How many participants were recruited, and of these how many develop
MCI?**

Totally 483 participants were recruited, of these 479 develop MCI.

**What is the average baseline age?**

The average baseline age is 65.0286013\`

**What proportion of women in the study are APOE4 carriers?**

The proportion of women in the study are APOE4 carriers is 0.3

``` r
#load mci_amyloid.csv file
amyloid <- read.csv("./data/mci_amyloid.csv",
                      skip = 1)
```

``` r
#clean amyloid dataset
amyloid_clean <- amyloid%>%
#clean and rename columns names reasonably
  janitor::clean_names()%>%
  rename(id = study_id,
         Baseline = baseline,
         After_two_year = time_2,
         After_four_year= time_4,
         After_six_year = time_6,
         After_eight_year = time_8)


#we also create a long table which convert After_X_year into one column and take values from them

amyloid_clean_long <- amyloid_clean%>%
  pivot_longer(Baseline:After_eight_year,names_to = "time", values_to = "beta_ratio")
```

**comment on the steps on the import process and the features of the
dataset.**

When reading the Amyloid data set, I skipped the first row in the excel
table and changed some unintelligible column names in the table to
reasonable column names to help us better merge the data sets. This data
set has a total of 487 rows and 6columns.key variables: id, Baseline,
After_two_year, After_four_year, After_six_year, After_eight_year

I also do another version, which convert this wide table into long table
by using each row to represent data at a specific time.This is achieved
through `pivot longer()` . After transforming, the dataset
`amyloid_clean_long` has 2435 rows and 3columns.key variables: id, time,
beta_ratio

**Check whether some participants appear in only the baseline or amyloid
datasets, and comment on your findings.**

``` r
# find the id appear in only the amyloid dataset
only_amyloid<-amyloid_clean%>%
  anti_join(baseline_filter,by = "id")

only_amyloid
```

    ##     id    Baseline After_two_year After_four_year After_six_year
    ## 1   72 0.106965463           <NA>     0.107266218    0.106665207
    ## 2  234 0.110521689    0.110988335     0.110318671    0.107334344
    ## 3  283 0.113436336    0.106568976      0.11338643     0.10820706
    ## 4  380 0.111158847    0.104560429     0.106822683    0.104961175
    ## 5  484  0.11139422    0.110936838     0.109182887    0.110607585
    ## 6  485 0.106042813    0.105158363     0.107758828    0.107281321
    ## 7  486 0.109161071    0.114634379            <NA>    0.110035156
    ## 8  487 0.110821971    0.107791347     0.109855229    0.110951271
    ## 9  488 0.110418756    0.111994328     0.113132987    0.108902038
    ## 10 489  0.11477384    0.113322128     0.115109381    0.116004489
    ## 11 490 0.111762756    0.109627815     0.111492905    0.110104053
    ## 12 491 0.116934974    0.113763228     0.111358448    0.110509854
    ## 13 492 0.109757685    0.109912273     0.110672861    0.109064952
    ## 14 493 0.108357146    0.108161281     0.109491179    0.104448142
    ## 15 494 0.116669151    0.109711076     0.112133216    0.111399722
    ## 16 495          Na    0.105142354     0.108149625    0.105918659
    ##    After_eight_year
    ## 1              <NA>
    ## 2       0.108868811
    ## 3       0.114399611
    ## 4       0.109506164
    ## 5       0.107057538
    ## 6       0.106181816
    ## 7       0.107234758
    ## 8       0.105861634
    ## 9       0.109449907
    ## 10      0.112260161
    ## 11             <NA>
    ## 12      0.110541984
    ## 13      0.109161341
    ## 14      0.108636703
    ## 15      0.108836759
    ## 16      0.102512562

``` r
# find the id appear in only the baseline dataset
only_baseline <- baseline_filter%>%
  anti_join(amyloid_clean,by = "id")


only_baseline
```

    ##    id current_age    sex education             apoe4 age_at_onset
    ## 1  14        58.4 Female        20 APOE4 non-carrier         66.2
    ## 2  49        64.7   Male        16 APOE4 non-carrier         68.4
    ## 3  92        68.6 Female        20 APOE4 non-carrier           NA
    ## 4 179        68.1   Male        16 APOE4 non-carrier           NA
    ## 5 268        61.4 Female        18     APOE4 carrier         67.5
    ## 6 304        63.8 Female        16 APOE4 non-carrier           NA
    ## 7 389        59.3 Female        16 APOE4 non-carrier           NA
    ## 8 412        67.0   Male        16     APOE4 carrier           NA

The data that exists in amyloid but not in baseline is the following
ID：72, 234, 283, 380, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493,
494, 495

The data that exists in baseline but not in amyloid is the following
ID：14, 49, 92, 179, 268, 304, 389, 412

There may be data loss, as all data from 484-495 are missing

**Combine the demographic and biomarker datasets so that only
participants who appear in both datasets are retained, and briefly
describe the resulting dataset; export the result as a CSV to your data
directory.**

``` r
#using inner_join to find the id appear in both dataset
combine_mci <- inner_join(baseline_clean,amyloid_clean_long,by = "id")

#combine wide table to show how many observations appear in both dataset
combine_observations <- inner_join(baseline_clean,amyloid_clean,by = "id")
```

``` r
#export the dataset
write.csv(combine_mci,file = "./data/combine mci.csv", row.names = TRUE)
```

After combination, there are totally 475 observations,and the dataset we
export has 2375rows, 8columns .The Key variables of this dataset are :
id, current_age, sex, education, apoe4, age_at_onset, time, beta_ratio.

where beta_ratio means the ratio value at `time`.
